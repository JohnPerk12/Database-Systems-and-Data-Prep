{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "I will be examining the 2014, 2015, and 2016 customer service survey for the SFO airport in San Francisco, California. This data set holds qualitative data relating to customer service metrics such as safety, residence location, cleanliness etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "######2015 Customer Service File Import#######\n",
    "CS_2015_Data_df=pd.read_csv('sfo_cust_sat_2015_data file_final_WEIGHTED_flysfo.csv')\n",
    "type(CS_2015_Data_df)\n",
    "CS_2015_Data_df.shape\n",
    "CS_2015_Data_df.columns\n",
    "CS_2015_Data_df.head\n",
    "\n",
    "######2016 Customer Service File Import#######\n",
    "CS_2016_xlfile=pd.ExcelFile('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/2016 SFO Customer Survey Data.xlsx')\n",
    "CS_2016_xlfile.sheet_names\n",
    "\n",
    "CS_2016_Data_df=pd.read_excel('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/2016 SFO Customer Survey Data.xlsx')\n",
    "type(CS_2016_Data_df)\n",
    "CS_2016_Data_df.shape\n",
    "CS_2016_Data_df.columns\n",
    "CS_2016_Data_df.dtypes\n",
    "CS_2016_Data_df.head() #displays the first amount of rows specified. If blank, it does 5\n",
    "CS_2016_Data_df.tail(3)#displays the last amount of rows specified. If blank, it does 5\n",
    "\n",
    "######2014 Customer Service File Import#######\n",
    "CS_2014_xlfile=pd.ExcelFile('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/sfo cust sat 2014 data file_WEIGHTED_flysfo.xlsx')\n",
    "CS_2014_xlfile.sheet_names\n",
    "\n",
    "CS_2014_Data_df=pd.read_excel('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/sfo cust sat 2014 data file_WEIGHTED_flysfo.xlsx')\n",
    "type(CS_2014_Data_df)\n",
    "CS_2014_Data_df.shape\n",
    "CS_2014_Data_df.columns\n",
    "CS_2014_Data_df.dtypes\n",
    "CS_2014_Data_df.head() #displays the first amount of rows specified. If blank, it does 5\n",
    "CS_2014_Data_df.tail(3)#displays the last amount of rows specified. If blank, it does 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "The variables in this part that were changed are qualitative variables. Variable names were changed in order to standardize them for analysis. The variable names are easier to remember, and are the same in the 2014, 2015, and 2016 data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modify Important Column Names 2014\n",
    "CS_2014_Data_df.rename(columns={'RESPNUM':'RESP_ID','DESTGEO':'REGION','Q7ART':'RATE_GEN_ART',\n",
    "   'Q7FOOD':'RATE_GEN_FOOD','Q7STORE':'RATE_GEN_STORE','Q7SIGN':'RATE_GEN_SIGN',\n",
    "   'Q7WALKWAYS':'RATE_GEN_WALKWAYS','Q7SCREENS':'RATE_GEN_SCREENS',\n",
    "   'Q7INFODOWN':'RATE_GEN_INFODOWN','Q7INFOUP':'RATE_GEN_INFOUP','Q7WIFI':'RATE_GEN_WIFI',\n",
    "   'Q7ROADS':'RATE_GEN_ROADS','Q7PARK':'RATE_GEN_PARK','Q7AIRTRAIN':'RATE_GEN_AIRTRAIN',\n",
    "   'Q7LTPARKING':'RATE_GEN_LTPARK','Q7RENTAL':'RATE_GEN_RENTAL','Q7ALL':'RATE_GEN_ALL',\n",
    "   'Q9BOARDING':'RATE_CLEAN_BOARDING','Q9AIRTRAIN':'RATE_CLEAN_AIRTRAIN',\n",
    "   'Q9RENTAL':'RATE_CLEAN_RENTAL','Q9FOOD':'RATE_CLEAN_FOOD','Q9RESTROOM':'RATE_CLEAN_RESTROOM',\n",
    "   'Q9ALL':'RATE_CLEAN_ALL','Q10SAFE':'RATE_SAFETY','Q12PRECHECKRATE':'RATE_PRECHK',\n",
    "   'Q13GETRATE':'RATE_GETEXP','Q14FIND':'RATE_FIND_WAY','Q14PASSTHRU':'RATE_PASS_TSA'}, inplace=True)\n",
    "\n",
    "#Modify Important Column Names 2015\n",
    "CS_2015_Data_df.rename(columns={'RESPNUM':'RESP_ID',\n",
    "    'DESTGEO':'REGION','Q7ART':'RATE_GEN_ART','Q7FOOD':'RATE_GEN_FOOD','Q7STORE':'RATE_GEN_STORE',\n",
    "    'Q7SIGN':'RATE_GEN_SIGN','Q7WALKWAYS':'RATE_GEN_WALKWAYS','Q7SCREENS':'RATE_GEN_SCREENS',\n",
    "    'Q7INFODOWN':'RATE_GEN_INFODOWN','Q7INFOUP':'RATE_GEN_INFOUP','Q7WIFI':'RATE_GEN_WIFI',\n",
    "    'Q7ROADS':'RATE_GEN_ROADS','Q7PARK':'RATE_GEN_PARK','Q7AIRTRAIN':'RATE_GEN_AIRTRAIN',\n",
    "    'Q7LTPARKING':'RATE_GEN_LTPARK','Q7RENTAL':'RATE_GEN_RENTAL','Q7ALL':'RATE_GEN_ALL',\n",
    "    'Q9BOARDING':'RATE_CLEAN_BOARDING','Q9AIRTRAIN':'RATE_CLEAN_AIRTRAIN','Q9RENTAL':'RATE_CLEAN_RENTAL',\n",
    "    'Q9FOOD':'RATE_CLEAN_FOOD','Q9RESTROOM':'RATE_CLEAN_RESTROOM','Q9ALL':'RATE_CLEAN_ALL',\n",
    "    'Q10SAFE':'RATE_SAFETY','Q12PRECHEKCRATE':'RATE_PRECHK','Q13GETRATE':'RATE_GETEXP',\n",
    "    'Q14FIND':'RATE_FIND_WAY','Q14PASSTHRU':'RATE_PASS_TSA'}, inplace=True)\n",
    "\n",
    "#Modify Important Column Names 2016\n",
    "CS_2016_Data_df.rename(columns={'*RESPNUM':'RESP_ID','DESTGEO':'REGION','Q7ART':'RATE_GEN_ART',\n",
    "   'Q7FOOD':'RATE_GEN_FOOD','Q7STORE':'RATE_GEN_STORE','Q7SIGN':'RATE_GEN_SIGN',\n",
    "   'Q7WALKWAYS':'RATE_GEN_WALKWAYS','Q7SCREENS':'RATE_GEN_SCREENS',\n",
    "   'Q7INFODOWN':'RATE_GEN_INFODOWN','Q7INFOUP':'RATE_GEN_INFOUP','Q7WIFI':'RATE_GEN_WIFI',\n",
    "   'Q7ROADS':'RATE_GEN_ROADS','Q7PARK':'RATE_GEN_PARK','Q7AIRTRAIN':'RATE_GEN_AIRTRAIN',\n",
    "   'Q7LTPARKING':'RATE_GEN_LTPARK','Q7RENTAL':'RATE_GEN_RENTAL','Q7ALL':'RATE_GEN_ALL',\n",
    "   'Q9BOARDING':'RATE_CLEAN_BOARDING','Q9AIRTRAIN':'RATE_CLEAN_AIRTRAIN',\n",
    "   'Q9RENTAL':'RATE_CLEAN_RENTAL','Q9FOOD':'RATE_CLEAN_FOOD','Q9RESTROOM':'RATE_CLEAN_RESTROOM',\n",
    "   'Q9ALL':'RATE_CLEAN_ALL','Q10SAFE':'RATE_SAFETY','Q12PRECHECKRATE':'RATE_PRECHK',\n",
    "   'Q13GETRATE':'RATE_GETEXP','Q14FIND':'RATE_FIND_WAY','Q14PASSTHRU':'RATE_PASS_TSA'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I double checked the code to ensure that the columns came out the way I would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Double Checking Columns\n",
    "CS_2014_Data_df.columns\n",
    "CS_2015_Data_df.columns\n",
    "CS_2016_Data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information in each of the dataframes was changed and manipulated so that I didn't have unnecessary information and columns. Notice that in the 2014 and 2016 dataframes, RATE_PRECHK had nan values. Each of the dataframes get bigger as the years go on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######---------------MANIPULATING 2014 DATA----------------------#############\n",
    "\n",
    "#Selecting Specific columns\n",
    "CS_2014_Data_INFO = CS_2014_Data_df[['RESP_ID','REGION','RATE_GEN_ART',\n",
    "   'RATE_GEN_FOOD','RATE_GEN_STORE','RATE_GEN_SIGN','RATE_GEN_WALKWAYS',\n",
    "   'RATE_GEN_SCREENS','RATE_GEN_INFODOWN','RATE_GEN_INFOUP','RATE_GEN_WIFI',\n",
    "   'RATE_GEN_ROADS','RATE_GEN_PARK','RATE_GEN_AIRTRAIN','RATE_GEN_LTPARK',\n",
    "   'RATE_GEN_RENTAL','RATE_GEN_ALL','RATE_CLEAN_BOARDING','RATE_CLEAN_AIRTRAIN',\n",
    "   'RATE_CLEAN_RENTAL','RATE_CLEAN_FOOD','RATE_CLEAN_RESTROOM','RATE_CLEAN_ALL',\n",
    "   'RATE_SAFETY','RATE_PRECHK','RATE_GETEXP','RATE_FIND_WAY','RATE_PASS_TSA','YEAR']]\n",
    "CS_2014_Data_INFO.head()\n",
    "\n",
    "#Check for right amount of records\n",
    "CS_2014_Data_INFO.shape\n",
    "\n",
    "#Check for every unique ID (2818)\n",
    "CS_2014_Data_INFO.RESP_ID.nunique()\n",
    "\n",
    "#See if there are any nan values (RATE_PRECHK has nan values)\n",
    "CS_2014_Data_INFO.notnull().sum()\n",
    "\n",
    "#Check RATE_PRECHK\n",
    "CS_2014_Data_INFO.RATE_PRECHK.head(6)\n",
    "\n",
    "#Distribution of values\n",
    "CS_2014_Data_INFO.RATE_PRECHK.value_counts().head()\n",
    "(CS_2014_Data_INFO.RATE_PRECHK==nan).sum()\n",
    "CS_2014_Data_INFO.RATE_PRECHK.value_counts(dropna=False).head()\n",
    "\n",
    "#Apply value counts to the subset of columns\n",
    "CS_2014_Data_df[['RATE_PRECHK']].apply(pd.value_counts)\n",
    "\n",
    "\n",
    "#######---------------MANIPULATING 2015 DATA----------------------#############\n",
    "\n",
    "#Selecting Specific columns\n",
    "CS_2015_Data_INFO = CS_2015_Data_df[['RESP_ID','REGION','RATE_GEN_ART',\n",
    "   'RATE_GEN_FOOD','RATE_GEN_STORE','RATE_GEN_SIGN','RATE_GEN_WALKWAYS',\n",
    "   'RATE_GEN_SCREENS','RATE_GEN_INFODOWN','RATE_GEN_INFOUP','RATE_GEN_WIFI',\n",
    "   'RATE_GEN_ROADS','RATE_GEN_PARK','RATE_GEN_AIRTRAIN','RATE_GEN_LTPARK',\n",
    "   'RATE_GEN_RENTAL','RATE_GEN_ALL','RATE_CLEAN_BOARDING','RATE_CLEAN_AIRTRAIN',\n",
    "   'RATE_CLEAN_RENTAL','RATE_CLEAN_FOOD','RATE_CLEAN_RESTROOM','RATE_CLEAN_ALL',\n",
    "   'RATE_SAFETY','RATE_PRECHK','RATE_GETEXP','RATE_FIND_WAY','RATE_PASS_TSA','YEAR']]\n",
    "CS_2015_Data_INFO.head()\n",
    "\n",
    "#Check for right amount of records\n",
    "CS_2015_Data_INFO.shape\n",
    "\n",
    "#Check for every unique ID (2598)\n",
    "CS_2015_Data_INFO.RESP_ID.nunique()\n",
    "\n",
    "#See if there are any nan values (There are no nan values)\n",
    "CS_2015_Data_INFO.notnull().sum()\n",
    "\n",
    "\n",
    "#######---------------MANIPULATING 2016 DATA----------------------#############\n",
    "\n",
    "#Selecting Specific columns\n",
    "CS_2016_Data_INFO = CS_2016_Data_df[['RESP_ID','REGION','RATE_GEN_ART',\n",
    "   'RATE_GEN_FOOD','RATE_GEN_STORE','RATE_GEN_SIGN','RATE_GEN_WALKWAYS',\n",
    "   'RATE_GEN_SCREENS','RATE_GEN_INFODOWN','RATE_GEN_INFOUP','RATE_GEN_WIFI',\n",
    "   'RATE_GEN_ROADS','RATE_GEN_PARK','RATE_GEN_AIRTRAIN','RATE_GEN_LTPARK',\n",
    "   'RATE_GEN_RENTAL','RATE_GEN_ALL','RATE_CLEAN_BOARDING','RATE_CLEAN_AIRTRAIN',\n",
    "   'RATE_CLEAN_RENTAL','RATE_CLEAN_FOOD','RATE_CLEAN_RESTROOM','RATE_CLEAN_ALL',\n",
    "   'RATE_SAFETY','RATE_PRECHK','RATE_GETEXP','RATE_FIND_WAY','RATE_PASS_TSA','YEAR']]\n",
    "CS_2014_Data_INFO.head()\n",
    "\n",
    "#Check for right amount of records\n",
    "CS_2016_Data_INFO.shape\n",
    "\n",
    "#Check for every unique ID (3087)\n",
    "CS_2016_Data_INFO.RESP_ID.nunique()\n",
    "\n",
    "#See if there are any nan values (There are no nan values)\n",
    "CS_2016_Data_INFO.notnull().sum()\n",
    "\n",
    "#Check RATE_PRECHK\n",
    "CS_2016_Data_INFO.RATE_PRECHK.head(6)\n",
    "\n",
    "#Distribution of values\n",
    "CS_2016_Data_INFO.RATE_PRECHK.value_counts().head()\n",
    "(CS_2016_Data_INFO.RATE_PRECHK==' ').sum()\n",
    "CS_2016_Data_INFO.RATE_PRECHK.value_counts(dropna=False).head()\n",
    "\n",
    "#Apply value counts to the subset of columns\n",
    "CS_2016_Data_df[['RATE_PRECHK']].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final databases were concatenated and exported as its own csv file. About half of the values for RATE_PRECHK in the years 2014 and 2016 were missing in the final csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###---Concatentate the databases---###\n",
    "\n",
    "CS_Data_df = pd.concat([CS_2014_Data_INFO, CS_2016_Data_INFO, CS_2015_Data_INFO])\n",
    "\n",
    "CS_Data_df.shape\n",
    "CS_Data_df.columns\n",
    "CS_Data_df.head()\n",
    "\n",
    "CS_Data_df.to_csv(\"CS_ALL_DATA.csv\",index=False)\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "For the second part of the analysis, I compiled the top three comments for men and women overall for the 2015 and 2016 datasets. For expediency of writing the code, I reset both of the original csv and excel files and saved them as the original dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "######2015 Customer Service File Import#######\n",
    "CS_2015_Data_df=pd.read_csv('sfo_cust_sat_2015_data file_final_WEIGHTED_flysfo.csv')\n",
    "type(CS_2015_Data_df)\n",
    "CS_2015_Data_df.shape\n",
    "CS_2015_Data_df.columns\n",
    "CS_2015_Data_df.head\n",
    "\n",
    "######2016 Customer Service File Import#######\n",
    "CS_2016_Data_df=pd.read_excel('2016 SFO Customer Survey Data.xlsx')\n",
    "type(CS_2016_Data_df)\n",
    "CS_2016_Data_df.shape\n",
    "CS_2016_Data_df.columns\n",
    "CS_2016_Data_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names were standardize to make the two easier to join. I also did checks for the distribution values to make sure that the information I was given was relatively normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Change 2015 column names-----###\n",
    "CS_2015_Data_df.rename(columns={'*RESPNUM':'RESP_ID',\n",
    "    'Q19GENDER':'Sex',\n",
    "    'Q8COM1':'2015_Comment 1',\n",
    "    'Q8COM2':'2015_Comment 2',\n",
    "    'Q8COM3':'2015_Comment 3',}, inplace=True)\n",
    "CS_2015_Data_df.columns\n",
    "\n",
    "CS_2015_Data_df.Sex.value_counts().head()#Check Distribution of values\n",
    "\n",
    "#Fix missing values to match other data frame form 2016\n",
    "CS_2015_Data_df.Sex.replace([1,2,0],['Male','Female','Other'], inplace=True)\n",
    "CS_2015_Data_df\n",
    "\n",
    "###-----Create new data frame-----###\n",
    "CS_2015_Info = CS_2015_Data_df[['Sex','2015_Comment 1','2015_Comment 2',\n",
    "   '2015_Comment 3']]\n",
    "CS_2015_Info.head()\n",
    "\n",
    "CS_2015_C1 = CS_2015_Info[['Sex','2015_Comment 1']].copy()\n",
    "CS_2015_C2 = CS_2015_Info[['Sex','2015_Comment 2']].copy()\n",
    "CS_2015_C3 = CS_2015_Info[['Sex','2015_Comment 3']].copy()\n",
    "\n",
    "CS_2015_C1.rename(columns ={'2015_Comment 1':'Comments'}, inplace=True)\n",
    "CS_2015_C2.rename(columns ={'2015_Comment 2':'Comments'}, inplace=True)\n",
    "CS_2015_C3.rename(columns ={'2015_Comment 3':'Comments'}, inplace=True)\n",
    "\n",
    "CS_2015_C1\n",
    "CS_2015_C2\n",
    "CS_2015_C3\n",
    "\n",
    "CS_2015_Comments_All_df = pd.concat([CS_2015_C1,CS_2015_C2,CS_2015_C3])\n",
    "\n",
    "###-----Change 2016 Column names-----###\n",
    "CS_2016_Data_df.rename(columns={'*RESPNUM':'RESP_ID',\n",
    "    'Q20GENDER':'Sex',\n",
    "    'Q8COM':'2016_Comment 1',\n",
    "    'Q8COM2':'2016_Comment 2',\n",
    "    'Q8COM3':'2016_Comment 3',\n",
    "    'Q8COM4':'2016_Comment 4',\n",
    "    'Q8COM5':'2016_Comment 5'}, inplace=True)\n",
    "CS_2016_Data_df\n",
    "CS_2016_Data_df.columns\n",
    "\n",
    "###-----Create new data frame-----###\n",
    "CS_2016_Info = CS_2016_Data_df[['Sex','2016_Comment 1','2016_Comment 2',\n",
    "   '2016_Comment 3','2016_Comment 4','2016_Comment 5']]\n",
    "CS_2016_Info.head(20)\n",
    "\n",
    "CS_2016_Info.Sex.value_counts().head() #Check Distribution of values\n",
    "\n",
    "CS_2016_C1 = CS_2016_Info[['Sex','2016_Comment 1']].copy()\n",
    "CS_2016_C2 = CS_2016_Info[['Sex','2016_Comment 2']].copy()\n",
    "CS_2016_C3 = CS_2016_Info[['Sex','2016_Comment 3']].copy()\n",
    "CS_2016_C4 = CS_2016_Info[['Sex','2016_Comment 4']].copy()\n",
    "CS_2016_C5 = CS_2016_Info[['Sex','2016_Comment 5']].copy()\n",
    "\n",
    "CS_2016_C1.rename(columns ={'2016_Comment 1':'Comments'}, inplace=True)\n",
    "CS_2016_C2.rename(columns ={'2016_Comment 2':'Comments'}, inplace=True)\n",
    "CS_2016_C3.rename(columns ={'2016_Comment 3':'Comments'}, inplace=True)\n",
    "CS_2016_C4.rename(columns ={'2016_Comment 4':'Comments'}, inplace=True)\n",
    "CS_2016_C5.rename(columns ={'2016_Comment 5':'Comments'}, inplace=True)\n",
    "\n",
    "CS_2016_C1\n",
    "CS_2016_C2\n",
    "CS_2016_C3\n",
    "CS_2016_C4\n",
    "CS_2016_C5\n",
    "\n",
    "CS_2016_Comments_All_df = pd.concat([CS_2016_C1,CS_2016_C2,CS_2016_C3,CS_2016_C4,\n",
    "    CS_2016_C5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final databases for the 2015 and 2016 databases can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---Final 2015 database---#\n",
    "CS_2015_Comments_All_df\n",
    "\n",
    "#---Final 2016 database---#\n",
    "CS_2016_Comments_All_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two final databses were combined to do the final analysis. For each year, male and female were split but then joined so that gender could be specifically displayed for the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########------------COMBINING THE DATA----------------#############\n",
    "\n",
    "CS_2015_Male = CS_2015_Comments_All_df[CS_2015_Comments_All_df.Sex=='Male']\n",
    "CS_2015_Male.head()\n",
    "\n",
    "CS_2015_Female = CS_2015_Comments_All_df[CS_2015_Comments_All_df.Sex=='Female']\n",
    "CS_2015_Female.head()\n",
    "\n",
    "CS_2016_Male = CS_2016_Comments_All_df[CS_2016_Comments_All_df.Sex=='Male']\n",
    "CS_2016_Male.head()\n",
    "\n",
    "CS_2016_Female = CS_2016_Comments_All_df[CS_2016_Comments_All_df.Sex=='Female']\n",
    "CS_2016_Female.head()\n",
    "\n",
    "CS_2015_Male.Comments.value_counts().nlargest(3)\n",
    "CS_2015_Male.Comments.value_counts().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The male and female data for each year was combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_Comments_All_df = pd.concat([CS_2015_Male,CS_2015_Female,CS_2016_Male,CS_2016_Female])\n",
    "CS_Comments_All_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information and frequencies were then grouped together to get the final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_Comments_ser = CS_Comments_All_df.groupby('Sex').Comments.value_counts()\n",
    "CS_Comments_ser\n",
    "\n",
    "CS_Comments_ser.groupby(level='Sex',group_keys=False).nlargest(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "The data in the excel and csv file was once again read in as new variables in order to do what is asked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "######2015 Customer Service File Import#######\n",
    "CS_2015_Data_Live=pd.read_csv('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/sfo_cust_sat_2015_data file_final_WEIGHTED_flysfo.csv')\n",
    "type(CS_2015_Data_df)\n",
    "CS_2015_Data_Live.shape\n",
    "CS_2015_Data_Live.columns\n",
    "CS_2015_Data_Live.head\n",
    "\n",
    "######2016 Customer Service File Import#######\n",
    "CS_2016_Data_Live=pd.read_excel('/Users/johnperkins/Dropbox (Personal)/Northwestern/5. Fall 2017/PREDICT 420/Assignment 1/2016 SFO Customer Survey Data.xlsx')\n",
    "type(CS_2016_Data_df)\n",
    "CS_2016_Data_Live.shape\n",
    "CS_2016_Data_Live.columns\n",
    "CS_2016_Data_Live.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names were changed in the 2015 set and the values for important variables were set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Change 2015 column names-----###\n",
    "CS_2015_Data_Live.rename(columns={'RESPNUM':'RESP_ID',\n",
    "    'Q19GENDER':'Sex',\n",
    "    'Q7ALL':'All_Comments','Q16LIVE':'Live_In'}, inplace=True)\n",
    "CS_2015_Data_Live.columns\n",
    "\n",
    "CS_2015_Data_Live.Live_In.value_counts().head()#Check Distribution of values\n",
    "\n",
    "#Fix values to match other data frame form 2016\n",
    "CS_2015_Data_Live.Live_In.replace([1,2,3,0],['County Bay Area','Northern California Outside Bay Area','In Another Region','Blank'], inplace=True)\n",
    "CS_2015_Data_Live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new 2015 data frame was created with only the variables I needed to do the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create new data frame-----###\n",
    "CS_2015_Live_Info = CS_2015_Data_Live[['Live_In','All_Comments']]\n",
    "CS_2015_Live_Info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names were changed in the 2016 set and the values for important variables were set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Change 2016 Column names-----###\n",
    "CS_2016_Data_Live.rename(columns={'*RESPNUM':'RESP_ID',\n",
    "    'Q20GENDER':'Sex',\n",
    "    'Q7ALL':'All_Comments','Q16LIVE':'Live_In'}, inplace=True)\n",
    "CS_2016_Data_Live\n",
    "CS_2016_Data_Live.columns\n",
    "\n",
    "#Fix missing values to match other data frame form 2015\n",
    "CS_2016_Data_Live.Live_In.replace([1,2,3,0],['County Bay Area','Northern California Outside Bay Area','In Another Region','Blank'], inplace=True)\n",
    "CS_2016_Data_Live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new 2016 data frame was created with only the variables I needed to do the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create new data frame-----###\n",
    "CS_2016_Live_Info = CS_2016_Data_Live[['Live_In','All_Comments']]\n",
    "CS_2016_Live_Info.head(20)\n",
    "\n",
    "CS_2016_Live_Info.Live_In.value_counts().head() #Check Distribution of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2015 and 2016 modified dataframes were combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########------------COMBINING THE DATA----------------#############\n",
    "#Combine both 2015 and 2016 data\n",
    "CS_All_Comments_df = pd.concat([CS_2016_Live_Info,CS_2015_Live_Info])\n",
    "CS_All_Comments_df\n",
    "\n",
    "CS_All_Comments_ser = CS_All_Comments_df.groupby('Live_In').All_Comments.value_counts()\n",
    "CS_All_Comments_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Live_IN variable was grouped by the frequency values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_All_Comments_ser.groupby(level='Live_In',group_keys=False).nlargest(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "The data in the excel and csv file was once again read in as new variables in order to do what is asked. This section evaluates demographic variables and attempts to describe travel behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "######Customer Select File Import#######\n",
    "CS_Select_Data_df=pd.read_csv('select_resps.csv')\n",
    "type(CS_Select_Data_df)\n",
    "CS_Select_Data_df\n",
    "CS_Select_Data_df.shape\n",
    "CS_Select_Data_df.columns\n",
    "CS_Select_Data_df.head\n",
    "\n",
    "######2015 Customer Service File Import#######\n",
    "CS_2015_Sel_Data_df=pd.read_csv('sfo_cust_sat_2015_data file_final_WEIGHTED_flysfo.csv')\n",
    "type(CS_2015_Sel_Data_df)\n",
    "CS_2015_Sel_Data_df.shape\n",
    "CS_2015_Sel_Data_df.columns\n",
    "CS_2015_Sel_Data_df.head\n",
    "\n",
    "######2016 Customer Service File Import#######\n",
    "CS_2016_Sel_Data_df=pd.read_excel('2016 SFO Customer Survey Data.xlsx')\n",
    "type(CS_2016_Sel_Data_df)\n",
    "CS_2016_Sel_Data_df.shape\n",
    "CS_2016_Sel_Data_df.columns\n",
    "CS_2016_Sel_Data_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the Select Customer and 2015 Customer Service dataframe were changed so that they were standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Change Select Customer column names-----###\n",
    "CS_Select_Data_df.rename(columns={'RESPNUM':'RESP_ID',\n",
    "    'year':'Year',}, inplace=True)\n",
    "CS_Select_Data_df.columns\n",
    "\n",
    "###-----Change 2015 column names-----###\n",
    "#This was performed to help with working with the columns. These names are easier\n",
    "#to understand\n",
    "CS_2015_Sel_Data_df.rename(columns={'RESPNUM':'RESP_ID',\n",
    "    'INTDATE':'Date_of_Interview','Q5TIMESFLOWN':'Times_Flown_SFO','Q6LONGUSE':'How_Long_Using_SFO','Q3PARK':'Parking'}, inplace=True)\n",
    "CS_2015_Sel_Data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values were changed and fixed in the 2015 CS dataframe so that the output would be clear to the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix values to match other data frame form 2016\n",
    "CS_2015_Sel_Data_df.Date_of_Interview.replace([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31],['2015-05-01 00:00:00',\n",
    "    '2015-05-02 00:00:00','2015-05-03 00:00:00','2015-05-04 00:00:00','2015-05-05 00:00:00',\n",
    "    '2015-05-06 00:00:00','2015-05-07 00:00:00','2015-05-08 00:00:00','2015-05-09 00:00:00',\n",
    "    '2015-05-10 00:00:00','2015-05-11 00:00:00','2015-05-12 00:00:00','2015-05-13 00:00:00',\n",
    "    '2015-05-14 00:00:00','2015-05-15 00:00:00','2015-05-16 00:00:00','2015-05-17 00:00:00',\n",
    "    '2015-05-18 00:00:00','2015-05-19 00:00:00','2015-05-20 00:00:00','2015-05-21 00:00:00',\n",
    "    '2015-05-22 00:00:00','2015-05-23 00:00:00','2015-05-24 00:00:00','2015-05-25 00:00:00',\n",
    "    '2015-05-26 00:00:00','2015-05-27 00:00:00','2015-05-28 00:00:00','2015-05-29 00:00:00',\n",
    "    '2015-05-30 00:00:00','2015-05-31 00:00:00'], inplace=True)\n",
    "CS_2015_Sel_Data_df\n",
    "\n",
    "CS_2015_Sel_Data_df.Times_Flown_SFO.replace([1,2,3,4,5,6,0],['1 Time','2 Times','3-6 Times','7-12 Times','13-24 Times','More than 24','Blank'], inplace=True)\n",
    "CS_2015_Sel_Data_df\n",
    "\n",
    "CS_2015_Sel_Data_df.How_Long_Using_SFO.replace([1,2,3,4,0],['Less than 1 Year','1-5 Years','6-10 Years','10+ Years','Blank'], inplace=True)\n",
    "CS_2015_Sel_Data_df\n",
    "\n",
    "CS_2015_Sel_Data_df.Parking.replace([1,2,3,4,0],['Domestic (Garage)','International Garage','SFO Long Term','Off-Airport','Blank'], inplace=True)\n",
    "CS_2015_Sel_Data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new dataframe was created with the changed variables and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create new data frame-----###\n",
    "CS_2015_Sel_Info = CS_2015_Sel_Data_df[['RESP_ID','Date_of_Interview','Times_Flown_SFO','How_Long_Using_SFO','Parking']]\n",
    "CS_2015_Sel_Info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the 2016 Customer Service dataframe were changed so that they were standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_2016_Sel_Data_df.rename(columns={'*RESPNUM':'RESP_ID','INTDATE':'Date_of_Interview',\n",
    "    'Q5TIMESFLOWN':'Times_Flown_SFO',\n",
    "    'Q6LONGUSE':'How_Long_Using_SFO',\n",
    "    'Q3PARK':'Parking'}, inplace=True)\n",
    "CS_2016_Sel_Data_df.columns\n",
    "CS_2016_Sel_Data_df\n",
    "\n",
    "#Fix missing values to match other data frame form 2016\n",
    "CS_2016_Sel_Data_df.Times_Flown_SFO.replace([1,2,3,4,5,6,0],['1 Time','2 Times','3-6 Times','7-12 Times','13-24 Times','More than 24','Blank'], inplace=True)\n",
    "CS_2016_Sel_Data_df\n",
    "\n",
    "CS_2016_Sel_Data_df.How_Long_Using_SFO.replace([1,2,3,4,0],['Less than 1 Year','1-5 Years','6-10 Years','10+ Years','Blank'], inplace=True)\n",
    "CS_2016_Sel_Data_df\n",
    "\n",
    "CS_2016_Sel_Data_df.Parking.replace([1,2,3,4,0],['Domestic (Garage)','International Garage','SFO Long Term','Off-Airport','Blank'], inplace=True)\n",
    "CS_2016_Sel_Data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new dataframe was created with the changed variables and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create new data frame-----###\n",
    "CS_2016_Sel_Info = CS_2016_Sel_Data_df[['RESP_ID','Date_of_Interview','Times_Flown_SFO','How_Long_Using_SFO','Parking']]\n",
    "CS_2016_Sel_Info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two new data frames for the 2015 and 2016 customer service dataframes were merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_Sel_All_df = pd.concat([CS_2015_Sel_Info,CS_2016_Sel_Info])\n",
    "CS_Sel_All_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate dataframe was created for the parking variable so that the frequency values could be displayed properly. The top 3 comments were displayed after being grouped by the respondent ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create New Data Frame for Parking-----###\n",
    "CS_2016_Sel_Park = CS_Sel_All_df[['RESP_ID','Parking']]\n",
    "CS_2016_Sel_Park.head()\n",
    "\n",
    "#Place all of the select passengers into a list for part c)\n",
    "CS_Select_List = CS_Select_Data_df.RESP_ID.tolist()\n",
    "CS_Select_List\n",
    "\n",
    "CS_2016_Sel_Park.RESP_ID.isin(CS_Select_List).head()\n",
    "\n",
    "CS_Select_Data_PARKFin = CS_2016_Sel_Park[CS_2016_Sel_Park.RESP_ID.isin(CS_Select_List)]\n",
    "CS_Select_Data_PARKFin\n",
    "\n",
    "CS_Select_Data_PARKFin.sort_values(by='RESP_ID')\n",
    "\n",
    "CS_All_Parking = CS_Select_Data_PARKFin.groupby('Parking').RESP_ID.value_counts()\n",
    "CS_All_Parking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate dataframe was created for the Times Flown variable so that the frequency values could be displayed properly. The top 3 comments were displayed after being grouped by the respondent ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Place all of the select passengers into a list for part c)\n",
    "CS_Select_List = CS_Select_Data_df.RESP_ID.tolist()\n",
    "CS_Select_List\n",
    "\n",
    "CS_2016_Sel_Times.RESP_ID.isin(CS_Select_List).head()\n",
    "\n",
    "CS_Select_Data_TimesFin = CS_2016_Sel_Times[CS_2016_Sel_Times.RESP_ID.isin(CS_Select_List)]\n",
    "CS_Select_Data_TimesFin\n",
    "\n",
    "CS_Select_Data_TimesFin.sort_values(by='RESP_ID')\n",
    "\n",
    "CS_All_Times = CS_Select_Data_TimesFin.groupby('Times_Flown_SFO').RESP_ID.value_counts()\n",
    "CS_All_Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate dataframe was created for the How Long Have You Been Using SFO variable so that the frequency values could be displayed properly. The top 3 comments were displayed after being grouped by the respondent ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###-----Create New Data Frame for How Long Using SFO-----###\n",
    "CS_2016_Sel_Long = CS_Sel_All_df[['RESP_ID','How_Long_Using_SFO']]\n",
    "CS_2016_Sel_Long.head()\n",
    "\n",
    "#Place all of the select passengers into a list for part c)\n",
    "CS_Select_List = CS_Select_Data_df.RESP_ID.tolist()\n",
    "CS_Select_List\n",
    "\n",
    "CS_2016_Sel_Long.RESP_ID.isin(CS_Select_List).head()\n",
    "\n",
    "CS_Select_Data_LongFin = CS_2016_Sel_Long[CS_2016_Sel_Long.RESP_ID.isin(CS_Select_List)]\n",
    "CS_Select_Data_LongFin\n",
    "\n",
    "CS_Select_Data_LongFin.sort_values(by='RESP_ID')\n",
    "\n",
    "CS_All_Long = CS_Select_Data_LongFin.groupby('How_Long_Using_SFO').RESP_ID.value_counts()\n",
    "CS_All_Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency tables for all of the variables are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Frequency table for all variables\n",
    "CS_All_Parking.groupby(level='Parking',group_keys=False).nlargest(3)\n",
    "CS_All_Times.groupby(level='Times_Flown_SFO',group_keys=False).nlargest(3)\n",
    "CS_All_Long.groupby(level='How_Long_Using_SFO',group_keys=False).nlargest(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "All of the databases created were pickled for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "CS_Data_df.to_pickle(Part_1.pk1)\n",
    "CS_Comments_ser.to_pickle(Part_2.pk1)\n",
    "CS_All_Comments_ser.to_pickle(Part_3.pk1)\n",
    "CS_All_Long.to_Pickle(Part_4_1.pk1)\n",
    "CS_All_Times.to_Pickle(Part_4_2.pk1)\n",
    "CS_All_Parking.to_Pickle(Part_4_3.pk1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
