{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrEx3\n",
    "For this assignment, I will be processing json files for perceptual mapping. This will include numeric perceptual mapping and text data for perceptual mapping. I will be exploring json files from customer service surveys for hotels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "Part 1 will be processing numeric perceptual mapping for the data. First I will import my packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from html.parser import HTMLParser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Imporing my packages, I will write a loop to process the files in my directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = os.listdir('.') \n",
    "file_list\n",
    "\n",
    "company_list=[]\n",
    "for file in file_list:\n",
    "    with open(file) as input_file:\n",
    "        jsondat = json.load(input_file)\n",
    "        reviews = jsondat['Reviews']\n",
    "        hotel_info = jsondat['HotelInfo']\n",
    "        reviews_df = json_normalize(reviews)\n",
    "        hotels_df = json_normalize(hotel_info)\n",
    "        reviews_df['HotelID'] = hotels_df.iloc[0]['HotelID']\n",
    "        df = pd.DataFrame(reviews_df)\n",
    "        company_list.append(df)\n",
    "        \n",
    "company_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the customer review files will have to be concattenated together for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_final = pd.concat(company_list)\n",
    "reviews_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another list will have to be compiled in order to retrive a hotel's name and have it added to each record. This was performed this way because in some cases, a hotel's name was not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_list = os.listdir('.') \n",
    "f_list\n",
    "\n",
    "hotel_list=[]\n",
    "\n",
    "for file in f_list:\n",
    "    with open(file) as input_file:\n",
    "        jsondat2 = json.load(input_file)\n",
    "        hotel_in = jsondat2['HotelInfo']\n",
    "        hotel_df = json_normalize(hotel_in)\n",
    "        hotel_list.append(hotel_df)\n",
    "hotel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hotel list was concattendated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hotel_final = pd.concat(hotel_list)\n",
    "hotel_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it was made into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hotel_final = pd.DataFrame(hotel_final)\n",
    "hotel_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup was used to take out the html tags and clean up the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup   #First install beautifulsoup4 using Canopy Package Manager\n",
    "soup = BeautifulSoup(hotel_final['Address'], 'html.parser')\n",
    "clean_address = soup.get_text().strip()    # get text and strip it of enclosing white space\n",
    "hotel_final['Address'] = clean_address     # save the clean address to the deal_info\n",
    "hotel_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hotel information was then normalized and merged with the reviews dataframe for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_final = json_normalize(hotel_final) #normalize the hotel dataframe\n",
    "        \n",
    "revs_df = reviews_final.merge(hotel_final) # merge the reviews dataframe with the hotel final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (b)\n",
    "The number of reviews for each hotel in the dataframe is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revs_df.groupby('HotelID').Title.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (c)\n",
    "The reported statistics describing the distribution of overall rating received by the hotels is found after checking the columns of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revs_df.columns #Check the column headers\n",
    "pd.to_numeric(revs_df['Ratings.Overall']) #Make sure the column is numeric\n",
    "\n",
    "revs_df['Ratings.Overall'].describe() #find the statistics of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (d)\n",
    "Save the dataframe by picking it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "revs_df.to_pickle(\"revs_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "In this part, the data from reviews in the json data will be transformed in order to do perceptual mapping and finding hot words. I first tested the hotwords propcess in finding comments with one file before moving on to do the full analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('72572.json') as input_file:\n",
    "    jsondat = json.load(input_file)\n",
    "\n",
    "jsondat.keys()\n",
    "jsondat['HotelInfo']\n",
    "hotel_info = jsondat['HotelInfo']\n",
    "hotel_info.keys()\n",
    "hotel_info['Address']\n",
    "reviews=jsondat['Reviews']\n",
    "len(reviews)\n",
    "reviews[0]\n",
    "reviews[0].keys()\n",
    "reviews[0]['Ratings']\n",
    "reviews[0]['Ratings']['Service']\n",
    "comments=reviews[0]['Content']\n",
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (1-2)\n",
    "Each hotel received a dictionary of comment content words and their frequencies and the counts of their occurences. A loop was written to process all json files at once instead of having to do each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_df_list = [] # to store the reviews DataFrame for each hotel\n",
    "hotWords = {} \n",
    "file_list = os.listdir('.') \n",
    "file_list\n",
    "for filename in file_list:\n",
    "   with open(filename) as input_file:\n",
    "    jsondat = json.load(input_file)\n",
    "    jsondat.keys()\n",
    "    hotel_info = jsondat['HotelInfo']\n",
    "    hotel_info.keys()\n",
    "    reviews = jsondat['Reviews']\n",
    "    reviews_df_list.append(reviews)\n",
    "    reviews = json_normalize(reviews)\n",
    "    reviews\n",
    "    reviews_df = pd.DataFrame(reviews)\n",
    "    comments = reviews_df['Content'].str.cat(sep=' ')\n",
    "    sentences = sent_tokenize(comments)\n",
    "    words = word_tokenize(comments)\n",
    "    cust_stop_words = set(stopwords.words('english')+list(punctuation))  \n",
    "    filtered_words = [word for sent in sentences for word in word_tokenize(sent) if word.lower() not in cust_stop_words]\n",
    "    filtered_words\n",
    "    fw_freq = nltk.FreqDist(filtered_words).most_common()  \n",
    "    fw_freq\n",
    "    hotWords[hotel_info['HotelID']] = fw_freq #Add the key HotelID with the value fw_freq to the dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (3)\n",
    "The hotWords dict was written for a json file and was verified that it was written correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json = json.dumps(hotWords)\n",
    "f = open(\"hotWords.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()\n",
    "\n",
    "with open(\"hotWords.json\", 'r') as fh:\n",
    "    hotWords = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (4)\n",
    "The number of unique content words in each of the hotel's dicts were counted and printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "print(Counter(chain.from_iterable(e,keys() for e in hotWords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also kept track of the most common hot words in each dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hotelID in hotWords:\n",
    "    print(hotelID,sorted(hotWords[hotelID])[:5])\n",
    "from collections import Counter\n",
    "\n",
    "for key in hotWords.keys():\n",
    "    print(key,Counter(hotWords[key]).most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
